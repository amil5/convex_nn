{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750474ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train neural networks on a synthetic classification dataset using convex optimization.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c520c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd .. && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from convex_nn.private.utils.data import gen_classification_data\n",
    "from convex_nn.optimize import optimize\n",
    "from convex_nn.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realizable synthetic classification problem (ie. Figure 1)\n",
    "n_train = 10000\n",
    "n_test = 10000\n",
    "d = 25\n",
    "hidden_units = 100\n",
    "kappa = 1000  # condition number\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = gen_classification_data(123, n_train, n_test, d, hidden_units, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "save_path = os.path.abspath('')\n",
    "\n",
    "train_dataset = datasets.CIFAR10(save_path, train=True, download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
    "    target_transform=lambda x: float(x >= 5))                            \n",
    "\n",
    "test_dataset = datasets.CIFAR10(save_path, train=False, download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), normalize,]),\n",
    "    target_transform=lambda x: float(x >= 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data via a dummy loader (dumps entire dataset at once)\n",
    "dummy_loader= torch.utils.data.DataLoader(train_dataset, batch_size=50000, shuffle=True, pin_memory=True, sampler=None)\n",
    "for X_train, y_train in dummy_loader:\n",
    "    pass\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_train = X_train[:n_train]\n",
    "y_train = y_train[:n_train]\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac232999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data via a dummy loader (dumps entire dataset at once)\n",
    "dummy_loader= torch.utils.data.DataLoader(test_dataset, batch_size=10000, shuffle=False, pin_memory=True, sampler=None)\n",
    "for X_test, y_test in dummy_loader:\n",
    "    pass\n",
    "\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "y_test = y_test[:n_test]\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0dfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, y):\n",
    "    return np.sum((np.sign(logits) == y)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cast data\n",
    "# tX_train, ty_train, tX_test, ty_test = [torch.tensor(z, dtype=torch.float) for z in [X_train, y_train, X_test, y_test]]\n",
    "\n",
    "# loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tX_train, ty_train), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7897edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "tol = 1e-6    \n",
    "lam = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a9d70d",
   "metadata": {},
   "source": [
    "## Non-Convex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.00001\n",
    "\n",
    "# # create model\n",
    "# nc_model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(in_features=d, out_features=hidden_units, bias=False), \n",
    "#     torch.nn.ReLU(), \n",
    "#     torch.nn.Linear(in_features=hidden_units, out_features=1, bias=False))\n",
    "\n",
    "# # Acc Before Training\n",
    "# print(\"Test Accuracy:\", accuracy(nc_model(tX_test).detach().numpy(), y_test))\n",
    "\n",
    "# sgd = torch.optim.SGD(nc_model.parameters(), lr=lr)\n",
    "\n",
    "# for i in range(max_epochs):\n",
    "#     for X, y in loader:\n",
    "#         nc_model.zero_grad()\n",
    "#         l2_penalty = sum([torch.sum(param ** 2) for param in nc_model.parameters()])\n",
    "#         obj = torch.sum((nc_model(X) - y) ** 2) / (2 * len(y)) + lam * l2_penalty\n",
    "#         obj.backward()\n",
    "        \n",
    "#         sgd.step()\n",
    "\n",
    "#     # check for convergence\n",
    "    \n",
    "#     nc_model.zero_grad()\n",
    "#     l2_penalty = sum([torch.sum(param ** 2) for param in nc_model.parameters()])\n",
    "#     obj = torch.sum((nc_model(tX_train) - ty_train) ** 2) / (2 * len(y_train)) + lam * l2_penalty\n",
    "#     obj.backward()    \n",
    "#     grad_norm = sum([torch.sum(param.grad ** 2) for param in nc_model.parameters()])\n",
    "\n",
    "#     if grad_norm <= tol:\n",
    "#         print(f\"Converged at {i}/{max_epochs}\")\n",
    "#         break\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         print(f\"{i}/{max_epochs}: Obj - {obj}, Grad - {grad_norm}\")\n",
    "\n",
    "# # Acc After Training\n",
    "# print(\"Test Accuracy:\", accuracy(nc_model(tX_test).detach().numpy(), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714dcc36",
   "metadata": {},
   "source": [
    "# Convex Reformulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ebb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvx_model, metrics = optimize(\"relu\", \n",
    "#                               max_neurons,\n",
    "#                               X_train=X_train[:10], \n",
    "#                               y_train=y_train[:10], \n",
    "#                               X_test=X_test.numpy(), \n",
    "#                               y_test=y_test.numpy(), \n",
    "#                               verbose=True,  \n",
    "#                               device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ec14f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "\n",
    "# number of activation patterns to use.\n",
    "max_neurons = 1000\n",
    "\n",
    "for num_examples in [100, 500, 1000]:\n",
    "    layers = []\n",
    "    for index in tqdm.tqdm(range(num_layers)):\n",
    "        if len(layers):\n",
    "            print(current_X_train.shape, layers[-1].shape)\n",
    "            current_X_train = np.maximum(current_X_train @ layers[-1].T, 0)\n",
    "            current_X_test = np.maximum(current_X_test @ layers[-1].T, 0)\n",
    "        else:\n",
    "            current_X_train = X_train[:num_examples]\n",
    "            current_X_test = X_test[:num_examples]\n",
    "\n",
    "        # train model\n",
    "        cvx_model, metrics = optimize(\"relu\", \n",
    "                                      max_neurons,\n",
    "                                      X_train=current_X_train[:num_examples], \n",
    "                                      y_train=y_train[:num_examples], \n",
    "                                      X_test=current_X_test.numpy(), \n",
    "                                      y_test=y_test.numpy(), \n",
    "                                      verbose=True,\n",
    "                                      regularizer=L2(1e-3),\n",
    "                                      device=\"cpu\")\n",
    "        layers.append(cvx_model.parameters[0])\n",
    "    layers.append(cvx_model.parameters[-1])\n",
    "    models[num_examples] = layers\n",
    "\n",
    "print([x.shape for x in layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709577d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Acc After Training\n",
    "print(\"\\n \\n\")\n",
    "print(\"Test Accuracy:\", accuracy(cvx_model(X_test.numpy()), y_test.numpy()))\n",
    "print(f\"Hidden Layer Size: {cvx_model.parameters[0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b57f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "for k, v in models.items():\n",
    "    with open(f\"model_{k}.json\", \"w\") as fp:\n",
    "        json.dump(v, fp, cls=NumpyEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
